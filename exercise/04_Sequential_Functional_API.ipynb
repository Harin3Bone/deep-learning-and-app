{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Keras Sequential Model and Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random, numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "np.set_printoptions(precision=2, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(logits):\n",
    "    exp_logits = np.exp(logits)\n",
    "    return exp_logits / np.sum(exp_logits)\n",
    "\n",
    "logits = np.array([2.0, 1.0, 0.1])\n",
    "probabilities = softmax(logits)\n",
    "print(probabilities, sum(probabilities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST data\n",
    "\n",
    "seed_value = 1234\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(-1, 28 * 28).astype(\"float32\") / 255.0\n",
    "x_test = x_test.reshape(-1, 28 * 28).astype(\"float32\") / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential Model (Very convenient, not very flexible)\n",
    "\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "model_1 = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(x_train.shape[-1],)),\n",
    "        layers.Dense(512, activation=\"relu\"),\n",
    "        layers.Dense(256, activation=\"relu\"),\n",
    "        layers.Dense(10),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model_1.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "model_1.fit(x_train, y_train, batch_size=32, epochs=5, verbose=2)\n",
    "print(\"\\nloss = {:.4f}, accuracy = {:.4f}\". format(*model_1.evaluate(x_test, y_test, batch_size=32, verbose=2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another way to use Sequential Model\n",
    "\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "\n",
    "model_1b = keras.Sequential()\n",
    "model_1b.add(keras.Input(shape=(x_train.shape[-1],)))\n",
    "model_1b.add(layers.Dense(512, activation=\"relu\", name=\"fc_layer1\"))\n",
    "model_1b.add(layers.Dense(256, activation=\"relu\", name=\"fc_layer2\"))\n",
    "model_1b.add(layers.Dense(10, name=\"outputs\"))\n",
    "\n",
    "model_1b.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model_1b.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_1b.fit(x_train, y_train, batch_size=32, epochs=5, verbose=2)\n",
    "print(\"\\nloss = {:.4f}, accuracy = {:.4f}\". format(*model_1b.evaluate(x_test, y_test, batch_size=32, verbose=2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "y_train_one_hot = to_categorical(y_train)\n",
    "y_test_one_hot = to_categorical(y_test)\n",
    "\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "\n",
    "model_1c = keras.Sequential()\n",
    "model_1c.add(keras.Input(shape=(x_train.shape[-1],)))\n",
    "model_1c.add(layers.Dense(512, activation=\"relu\", name=\"fc_layer1\"))\n",
    "model_1c.add(layers.Dense(256, activation=\"relu\", name=\"fc_layer2\"))\n",
    "model_1c.add(layers.Dense(10, activation=\"softmax\", name=\"outputs\"))\n",
    "\n",
    "model_1c.compile(\n",
    "    loss=keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model_1c.summary()\n",
    "\n",
    "model_1c.fit(x_train, y_train_one_hot, batch_size=32, epochs=5, verbose=2)\n",
    "print(\"\\nloss = {:.4f}, accuracy = {:.4f}\". format(*model_1c.evaluate(x_test, y_test_one_hot, batch_size=32, verbose=2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_1c.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((y_test == y_pred.argmax(axis=1)).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functional API (A bit more flexible)\n",
    "\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "\n",
    "inputs = keras.Input(shape=(x_train.shape[-1],), name=\"inputs\")\n",
    "x = layers.Dense(512, activation=\"relu\", name=\"fc_layer1\")(inputs)\n",
    "x = layers.Dense(256, activation=\"relu\", name=\"fc_layer2\")(x)\n",
    "outputs = layers.Dense(10, activation=\"softmax\", name=\"outputs\")(x)\n",
    "\n",
    "model_2 = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model_2.summary()\n",
    "\n",
    "model_2.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "model_2.fit(x_train, y_train, batch_size=32, epochs=5, verbose=2)\n",
    "print(\"\\nloss = {:.4f}, accuracy = {:.4f}\". format(*model_2.evaluate(x_test, y_test, batch_size=32, verbose=2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More on Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functional API (A bit more flexible)\n",
    "\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "\n",
    "inputs = keras.Input(shape=(x_train.shape[-1],), name=\"inputs\")\n",
    "x1 = layers.Dense(512, activation=\"relu\", name=\"fc_layer1\")(inputs)\n",
    "x2 = layers.Dense(256, activation=\"relu\", name=\"fc_layer2\")(x1)\n",
    "x = layers.Concatenate(axis=1, name=\"concat_layer1\")([x1, x2])\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"fc_layer3\")(x)\n",
    "outputs = layers.Dense(10, activation=\"softmax\", name=\"outputs\")(x)\n",
    "\n",
    "model_3 = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model_3.summary()\n",
    "\n",
    "model_3.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "model_3.fit(x_train, y_train, batch_size=32, epochs=5, verbose=2)\n",
    "print(\"\\nloss = {:.4f}, accuracy = {:.4f}\". format(*model_3.evaluate(x_test, y_test, batch_size=32, verbose=2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_wsl_364",
   "language": "python",
   "name": "dl_wsl_364"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
